# ğŸŒ¬ï¸ Airflow ETL Pipeline - Remote Jobs

Pipeline de datos construido con **Apache Airflow** que extrae ofertas de trabajo remoto desde la API de [Remotive](https://remotive.com), las transforma y genera un archivo CSV limpio.

## ğŸ“ Estructura del Proyecto
Airflow_Proyect/
â”œâ”€â”€ dags/
â”‚ â”œâ”€â”€ helpers/
â”‚ â”‚ â”œâ”€â”€ extract.py # ExtracciÃ³n desde API
â”‚ â”‚ â”œâ”€â”€ transform.py # Limpieza de datos
â”‚ â”‚ â””â”€â”€ load.py # Carga a CSV
â”‚ â”œâ”€â”€ data/
â”‚ â”‚ â”œâ”€â”€ raw/ # JSON descargados (generado)
â”‚ â”‚ â””â”€â”€ processed/ # CSV final (generado)
â”‚ â”œâ”€â”€ job_etl_dag.py # DAG principal del ETL
â”‚ â””â”€â”€ primer_dag.py # DAG de prueba
â”œâ”€â”€ plugins/ # Plugins personalizados de Airflow
â”œâ”€â”€ logs/ # Logs de ejecuciÃ³n (generado)
â”œâ”€â”€ docker-compose.yaml # ConfiguraciÃ³n de Docker
â”œâ”€â”€ requirements.txt # Dependencias Python
â””â”€â”€ README.md


## ğŸš€ CÃ³mo Ejecutar

### Prerrequisitos
- [Docker Desktop](https://www.docker.com/products/docker-desktop/)
- Git

### Pasos

1. **Clonar el repositorio**
   
   git clone https://github.com/tu-usuario/Airflow_Proyect.git
   cd Airflow_Proyect
   2. **Levantar los contenedores**
   
   docker-compose up -d
   3. **Esperar 1-2 minutos** para que Airflow inicialice

4. **Acceder a Airflow UI**
   - URL: http://localhost:8080
   - Usuario: `admin`
   - ContraseÃ±a: `admin`

5. **Ejecutar el DAG**
   - Activar el toggle de `job_etl_pipeline`
   - Click en "Trigger DAG" â–¶ï¸

### Detener el proyecto
docker-compose down## ğŸ“Š DAGs Disponibles

| DAG | DescripciÃ³n | Schedule |
|-----|-------------|----------|
| `primer_dag_prueba` | DAG de prueba con un simple "Hola Mundo" | Diario |
| `job_etl_pipeline` | Pipeline ETL completo de trabajos remotos | Diario |

## ğŸ”„ Flujo del ETL
Levantar los contenedores
   docker-compose up -dga trabajos desde Remotive API
2. **Transform**: Limpia y estructura los datos
3. **Load**: Genera archivo `jobs.csv`

## ğŸ› ï¸ TecnologÃ­as

- **Apache Airflow 2.9.0** - OrquestaciÃ³n de workflows
- **PostgreSQL 15** - Base de datos de metadatos
- **Docker & Docker Compose** - ContenedorizaciÃ³n
- **Python 3.12** - Lenguaje de programaciÃ³n



## âœ… Estructura final

Airflow_Proyect/
â”œâ”€â”€ dags/
â”‚ â”œâ”€â”€ helpers/
â”‚ â”‚ â”œâ”€â”€ extract.py
â”‚ â”‚ â”œâ”€â”€ transform.py
â”‚ â”‚ â””â”€â”€ load.py
â”‚ â”œâ”€â”€ data/ # carpeta vacÃ­a o con .gitkeep
â”‚ â”œâ”€â”€ job_etl_dag.py
â”‚ â””â”€â”€ primer_dag.py
â”œâ”€â”€ plugins/ # puede estar vacÃ­a
â”œâ”€â”€ docker-compose.yaml
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md

